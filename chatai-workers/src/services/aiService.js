/**
 * AI æœåŠ¡
 * é›†æˆå¤šä¸ªAIæä¾›å•†ï¼Œå¤„ç†æ™ºèƒ½å¯¹è¯ï¼Œæ”¯æŒå¯†é’¥è½®æ¢
 */

// å…¨å±€é…é¢çŠ¶æ€ï¼ˆåœ¨Workersä¸­æŒä¹…åŒ–ï¼‰
let globalQuotaStatus = {
  gemini: {
    dailyLimit: 1500,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'Google Gemini',
    icon: 'ğŸ”®'
  },
  groq: {
    dailyLimit: 1000,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'Groq',
    icon: 'âš¡'
  },
  openai: {
    dailyLimit: null, // ä»˜è´¹æœåŠ¡ï¼Œæ— å›ºå®šé™åˆ¶
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'OpenAI GPT',
    icon: 'ğŸš€'
  },
  anthropic: {
    dailyLimit: null,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'Anthropic Claude',
    icon: 'ğŸ§ '
  },
  qwen: {
    dailyLimit: 500,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'é€šä¹‰åƒé—®',
    icon: 'ğŸ‡¨ğŸ‡³'
  },
  zhipu: {
    dailyLimit: 200,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'æ™ºè°±AI',
    icon: 'ğŸ‡¨ğŸ‡³'
  },
  deepseek: {
    dailyLimit: 300,
    used: 0,
    resetTime: null,
    lastError: null,
    name: 'DeepSeek',
    icon: 'ğŸ‡¨ğŸ‡³'
  }
}

export class AIService {
  constructor(env) {
    this.env = env

    // åˆå§‹åŒ–å¯†é’¥æ± 
    this.initializeKeyPools(env)

    // ä½¿ç”¨å…¨å±€é…é¢çŠ¶æ€
    this.quotaStatus = globalQuotaStatus
  }

  // åˆå§‹åŒ–å¯†é’¥æ± 
  initializeKeyPools(env) {
    this.keyPools = {
      // å›½å¤–AIå¹³å°
      openai: {
        keys: this.parseKeys(env.OPENAI_API_KEYS || env.OPENAI_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.openai.com/v1',
        model: 'gpt-4.1-2025-04-14',
        failedKeys: new Set()
      },
      anthropic: {
        keys: this.parseKeys(env.ANTHROPIC_API_KEYS || env.ANTHROPIC_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.anthropic.com/v1',
        model: 'claude-opus-4.1',
        failedKeys: new Set()
      },
      gemini: {
        keys: this.parseKeys(env.GEMINI_API_KEYS || env.GEMINI_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://generativelanguage.googleapis.com/v1beta',
        model: 'gemini-2.5-pro',
        failedKeys: new Set()
      },

      // æ›´å¤šå›½å¤–AIå¹³å°
      cohere: {
        keys: this.parseKeys(env.COHERE_API_KEYS || env.COHERE_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.cohere.ai/v1',
        model: 'command-a',
        failedKeys: new Set()
      },
      mistral: {
        keys: this.parseKeys(env.MISTRAL_API_KEYS || env.MISTRAL_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.mistral.ai/v1',
        model: 'codestral-2501',
        failedKeys: new Set()
      },
      perplexity: {
        keys: this.parseKeys(env.PERPLEXITY_API_KEYS || env.PERPLEXITY_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.perplexity.ai',
        model: 'sonar-pro',
        failedKeys: new Set()
      },
      groq: {
        keys: this.parseKeys(env.GROQ_API_KEYS || env.GROQ_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.groq.com/openai/v1',
        model: 'llama-4-maverick',
        failedKeys: new Set()
      },
      together: {
        keys: this.parseKeys(env.TOGETHER_API_KEYS || env.TOGETHER_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.together.xyz/v1',
        model: 'meta-llama/llama-4-scout',
        failedKeys: new Set()
      },
      fireworks: {
        keys: this.parseKeys(env.FIREWORKS_API_KEYS || env.FIREWORKS_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.fireworks.ai/inference/v1',
        model: 'accounts/fireworks/models/deepseek-v3',
        failedKeys: new Set()
      },
      replicate: {
        keys: this.parseKeys(env.REPLICATE_API_KEYS || env.REPLICATE_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.replicate.com/v1',
        model: 'meta/llama-4-maverick',
        failedKeys: new Set()
      },
      huggingface: {
        keys: this.parseKeys(env.HUGGINGFACE_API_KEYS || env.HUGGINGFACE_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api-inference.huggingface.co/models',
        model: 'Qwen/Qwen3-235B-A22B',
        failedKeys: new Set()
      },

      // ä¸­å›½å›½å†…AIå¹³å°
      qwen: {
        keys: this.parseKeys(env.QWEN_API_KEYS || env.QWEN_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://dashscope.aliyuncs.com/api/v1',
        model: 'qwen-max-2025-01-25',
        failedKeys: new Set()
      },
      baidu: {
        keys: this.parseKeys(env.BAIDU_API_KEYS || env.BAIDU_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat',
        model: 'ernie-4.0-turbo-8k',
        failedKeys: new Set()
      },
      zhipu: {
        keys: this.parseKeys(env.ZHIPU_API_KEYS || env.ZHIPU_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://open.bigmodel.cn/api/paas/v4',
        model: 'glm-4.5-air',
        failedKeys: new Set()
      },
      moonshot: {
        keys: this.parseKeys(env.MOONSHOT_API_KEYS || env.MOONSHOT_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.moonshot.cn/v1',
        model: 'kimi-k2-preview',
        failedKeys: new Set()
      },
      deepseek: {
        keys: this.parseKeys(env.DEEPSEEK_API_KEYS || env.DEEPSEEK_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.deepseek.com/v1',
        model: 'deepseek-v3',
        failedKeys: new Set()
      },
      minimax: {
        keys: this.parseKeys(env.MINIMAX_API_KEYS || env.MINIMAX_API_KEY),
        currentIndex: 0,
        baseUrl: 'https://api.minimax.chat/v1',
        model: 'MiniMax-Text-01',
        failedKeys: new Set()
      }
    }
  }

  // è§£æå¯†é’¥å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
  parseKeys(keyString) {
    if (!keyString) return []

    // æ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šé€—å·ã€åˆ†å·ã€æ¢è¡Œç¬¦
    const keys = keyString
      .split(/[,;\n]/)
      .map(key => key.trim())
      .filter(key => key.length > 0)

    console.log(`Parsed ${keys.length} keys from: ${keyString.substring(0, 20)}...`)
    return keys
  }

  // è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„APIå¯†é’¥
  getNextApiKey(providerName) {
    const pool = this.keyPools[providerName]
    if (!pool || !pool.keys || pool.keys.length === 0) {
      throw new Error(`No API keys configured for provider: ${providerName}`)
    }

    // å¦‚æœæ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥äº†ï¼Œé‡ç½®å¤±è´¥çŠ¶æ€
    if (pool.failedKeys.size >= pool.keys.length) {
      console.log(`All keys failed for ${providerName}, resetting failed keys`)
      pool.failedKeys.clear()
      pool.currentIndex = 0
    }

    // å¯»æ‰¾ä¸‹ä¸€ä¸ªå¯ç”¨çš„å¯†é’¥
    let attempts = 0
    while (attempts < pool.keys.length) {
      const currentKey = pool.keys[pool.currentIndex]

      if (!pool.failedKeys.has(currentKey)) {
        console.log(`Using key ${pool.currentIndex + 1}/${pool.keys.length} for ${providerName}`)
        return {
          key: currentKey,
          index: pool.currentIndex,
          baseUrl: pool.baseUrl,
          model: pool.model
        }
      }

      // ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥
      pool.currentIndex = (pool.currentIndex + 1) % pool.keys.length
      attempts++
    }

    throw new Error(`No available API keys for provider: ${providerName}`)
  }

  // æ ‡è®°å¯†é’¥ä¸ºå¤±è´¥çŠ¶æ€
  markKeyAsFailed(providerName, keyIndex, error) {
    const pool = this.keyPools[providerName]
    if (!pool || !pool.keys[keyIndex]) return

    const failedKey = pool.keys[keyIndex]
    pool.failedKeys.add(failedKey)

    console.log(`Marked key ${keyIndex + 1}/${pool.keys.length} as failed for ${providerName}: ${error}`)

    // ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥
    pool.currentIndex = (keyIndex + 1) % pool.keys.length
  }

  // é‡ç½®å¯†é’¥çŠ¶æ€ï¼ˆç”¨äºå®šæœŸæ¸…ç†ï¼‰
  resetKeyStatus(providerName) {
    const pool = this.keyPools[providerName]
    if (pool) {
      pool.failedKeys.clear()
      pool.currentIndex = 0
      console.log(`Reset key status for ${providerName}`)
    }
  }

  // é€šç”¨é…é¢ç®¡ç†æ–¹æ³•
  async updateQuotaStatus(providerName, success, errorType = null, env = null) {
    // ç¡®ä¿é…é¢å¯¹è±¡å­˜åœ¨ï¼Œå¹¶ä¿æŒåŸæœ‰çš„dailyLimitè®¾ç½®
    if (!this.quotaStatus[providerName]) {
      // ä»å…¨å±€é…é¢çŠ¶æ€è·å–é»˜è®¤é…ç½®
      const defaultQuota = globalQuotaStatus[providerName]
      this.quotaStatus[providerName] = {
        dailyLimit: defaultQuota ? defaultQuota.dailyLimit : null,
        used: 0,
        resetTime: null,
        lastError: null,
        name: defaultQuota ? defaultQuota.name : providerName,
        icon: defaultQuota ? defaultQuota.icon : 'ğŸ¤–'
      }
    }

    const quota = this.quotaStatus[providerName]
    const now = new Date()
    const today = now.toDateString()

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ï¼ˆåªåœ¨çœŸæ­£æ˜¯æ–°çš„ä¸€å¤©æ—¶é‡ç½®ï¼‰
    if (!quota.resetTime) {
      // ç¬¬ä¸€æ¬¡åˆå§‹åŒ–ï¼Œè®¾ç½®é‡ç½®æ—¶é—´ä¸ºæ˜å¤©
      quota.resetTime = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1).toISOString()
    } else if (new Date(quota.resetTime).toDateString() !== today && new Date(quota.resetTime) <= now) {
      // çœŸæ­£æ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®é…é¢
      quota.used = 0
      quota.resetTime = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1).toISOString()
      quota.lastError = null
      console.log(`Reset quota for ${providerName} - new day`)
    }

    // ç¡®ä¿dailyLimitä¸ä¼šè¢«é‡ç½®ï¼Œä»å…¨å±€çŠ¶æ€æ¢å¤ï¼ˆä½†ä¸é‡ç½®usedï¼‰
    const defaultQuota = globalQuotaStatus[providerName]
    if (defaultQuota && quota.dailyLimit !== defaultQuota.dailyLimit) {
      quota.dailyLimit = defaultQuota.dailyLimit
      quota.name = defaultQuota.name
      quota.icon = defaultQuota.icon
    }

    if (success) {
      quota.used += 1
      quota.lastError = null
    } else {
      quota.lastError = errorType
    }

    console.log(`Updated quota for ${providerName}:`, quota)

    // æŒä¹…åŒ–åˆ°KVå­˜å‚¨
    if (env && env.CHAT_STORAGE) {
      try {
        const quotaKey = `quota:${providerName}:${today}`
        await env.CHAT_STORAGE.put(quotaKey, JSON.stringify(quota))
        console.log(`Persisted quota for ${providerName} to KV storage`)
      } catch (error) {
        console.error(`Failed to persist quota for ${providerName}:`, error)
      }
    }
  }

  // ä»KVå­˜å‚¨åŠ è½½é…é¢çŠ¶æ€
  async loadQuotaFromKV(providerName, env) {
    if (!env || !env.CHAT_STORAGE) return null

    try {
      const today = new Date().toDateString()
      const quotaKey = `quota:${providerName}:${today}`
      const quotaData = await env.CHAT_STORAGE.get(quotaKey)

      if (quotaData) {
        const quota = JSON.parse(quotaData)
        console.log(`Loaded quota for ${providerName} from KV:`, quota)
        return quota
      }
    } catch (error) {
      console.error(`Failed to load quota for ${providerName} from KV:`, error)
    }

    return null
  }

  // è·å–çœŸå®çš„APIé…é¢ä¿¡æ¯
  async getRealQuotaFromAPI(providerName) {
    try {
      const provider = this.keyPools[providerName]
      if (!provider || !provider.keys || provider.keys.length === 0) {
        return null
      }

      const apiKey = provider.keys[provider.currentIndex]
      if (!apiKey) return null

      switch (providerName) {
        case 'gemini':
          return await this.getGeminiRealQuota(apiKey)
        case 'openai':
          return await this.getOpenAIRealQuota(apiKey)
        case 'anthropic':
          return await this.getAnthropicRealQuota(apiKey)
        case 'qwen':
          return await this.getQwenRealQuota(apiKey)
        case 'zhipu':
          return await this.getZhipuRealQuota(apiKey)
        case 'deepseek':
          return await this.getDeepSeekRealQuota(apiKey)
        case 'moonshot':
          return await this.getMoonshotRealQuota(apiKey)
        case 'groq':
          return await this.getGroqRealQuota(apiKey)
        default:
          return null
      }
    } catch (error) {
      console.error(`Failed to get real quota for ${providerName}:`, error)
      return null
    }
  }

  // GeminiçœŸå®é…é¢æŸ¥è¯¢
  async getGeminiRealQuota(apiKey) {
    try {
      // Geminiæ²¡æœ‰ç›´æ¥çš„é…é¢æŸ¥è¯¢APIï¼Œé€šè¿‡æµ‹è¯•è¯·æ±‚åˆ¤æ–­
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`,
        { method: 'GET' }
      )

      if (response.ok) {
        return {
          dailyLimit: 1500, // Geminiå…è´¹ç‰ˆæ¯æ—¥é™åˆ¶
          available: true,
          source: 'api_test'
        }
      } else if (response.status === 429) {
        return {
          dailyLimit: 1500,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // OpenAIçœŸå®é…é¢æŸ¥è¯¢
  async getOpenAIRealQuota(apiKey) {
    try {
      // OpenAIé…é¢æŸ¥è¯¢API
      const response = await fetch(
        'https://api.openai.com/v1/usage',
        {
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          }
        }
      )

      if (response.ok) {
        const data = await response.json()
        return {
          dailyLimit: null, // ä»˜è´¹æœåŠ¡ï¼Œæ— å›ºå®šé™åˆ¶
          available: true,
          source: 'api_real',
          usage: data
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // AnthropicçœŸå®é…é¢æŸ¥è¯¢
  async getAnthropicRealQuota(apiKey) {
    try {
      // Anthropicæ²¡æœ‰å…¬å¼€çš„é…é¢æŸ¥è¯¢APIï¼Œé€šè¿‡æµ‹è¯•è¯·æ±‚åˆ¤æ–­
      const response = await fetch(
        'https://api.anthropic.com/v1/messages',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
            'anthropic-version': '2023-06-01'
          },
          body: JSON.stringify({
            model: 'claude-3-haiku-20240307',
            max_tokens: 1,
            messages: [{ role: 'user', content: 'test' }]
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: null,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: null, // ä»˜è´¹æœåŠ¡
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // é€šä¹‰åƒé—®çœŸå®é…é¢æŸ¥è¯¢
  async getQwenRealQuota(apiKey) {
    try {
      // é€šä¹‰åƒé—®æ²¡æœ‰ç›´æ¥çš„é…é¢æŸ¥è¯¢APIï¼Œé€šè¿‡æµ‹è¯•è¯·æ±‚åˆ¤æ–­
      const response = await fetch(
        'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'qwen-turbo',
            input: { messages: [{ role: 'user', content: 'test' }] },
            parameters: { max_tokens: 1 }
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: 500,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: 500, // å…è´¹ç‰ˆé™åˆ¶
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // æ™ºè°±AIçœŸå®é…é¢æŸ¥è¯¢
  async getZhipuRealQuota(apiKey) {
    try {
      // æ™ºè°±AIæ²¡æœ‰ç›´æ¥çš„é…é¢æŸ¥è¯¢APIï¼Œé€šè¿‡æµ‹è¯•è¯·æ±‚åˆ¤æ–­
      const response = await fetch(
        'https://open.bigmodel.cn/api/paas/v4/chat/completions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'glm-4',
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: 200,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: 200, // å…è´¹ç‰ˆé™åˆ¶
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // DeepSeekçœŸå®é…é¢æŸ¥è¯¢
  async getDeepSeekRealQuota(apiKey) {
    try {
      const response = await fetch(
        'https://api.deepseek.com/v1/chat/completions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'deepseek-chat',
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: 300,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: 300, // å…è´¹ç‰ˆé™åˆ¶
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // MoonshotçœŸå®é…é¢æŸ¥è¯¢
  async getMoonshotRealQuota(apiKey) {
    try {
      const response = await fetch(
        'https://api.moonshot.cn/v1/chat/completions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'moonshot-v1-8k',
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: null, // ä»˜è´¹æœåŠ¡
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: null, // ä»˜è´¹æœåŠ¡
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // GroqçœŸå®é…é¢æŸ¥è¯¢
  async getGroqRealQuota(apiKey) {
    try {
      const response = await fetch(
        'https://api.groq.com/openai/v1/chat/completions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'llama3-8b-8192',
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          })
        }
      )

      if (response.status === 429) {
        return {
          dailyLimit: 1000,
          available: false,
          source: 'api_test',
          error: 'quota_exceeded'
        }
      } else if (response.ok || response.status === 400) {
        return {
          dailyLimit: 1000, // å…è´¹ç‰ˆé™åˆ¶
          available: true,
          source: 'api_test'
        }
      }
      return null
    } catch (error) {
      return null
    }
  }

  // æ£€æŸ¥é…é¢çŠ¶æ€ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒçœŸå®APIæŸ¥è¯¢ï¼‰
  async checkQuotaStatus(providerName, env = null) {
    // ç¡®ä¿é…é¢å¯¹è±¡å­˜åœ¨ï¼Œå¹¶ä»å…¨å±€çŠ¶æ€è·å–é»˜è®¤é…ç½®
    if (!this.quotaStatus[providerName]) {
      const defaultQuota = globalQuotaStatus[providerName]
      this.quotaStatus[providerName] = {
        dailyLimit: defaultQuota ? defaultQuota.dailyLimit : null,
        used: 0,
        resetTime: null,
        lastError: null,
        name: defaultQuota ? defaultQuota.name : providerName,
        icon: defaultQuota ? defaultQuota.icon : 'ğŸ¤–'
      }
    }

    // å°è¯•ä»KVå­˜å‚¨åŠ è½½æœ€æ–°çŠ¶æ€
    if (env) {
      const kvQuota = await this.loadQuotaFromKV(providerName, env)
      if (kvQuota) {
        // åˆå¹¶KVæ•°æ®ï¼Œä½†ä¿æŒå…¨å±€é…ç½®çš„dailyLimitã€nameã€icon
        const defaultQuota = globalQuotaStatus[providerName]
        this.quotaStatus[providerName] = {
          ...kvQuota,
          dailyLimit: defaultQuota ? defaultQuota.dailyLimit : kvQuota.dailyLimit,
          name: defaultQuota ? defaultQuota.name : kvQuota.name,
          icon: defaultQuota ? defaultQuota.icon : kvQuota.icon
        }
      }
    }

    // å°è¯•è·å–çœŸå®çš„APIé…é¢ä¿¡æ¯
    const realQuota = await this.getRealQuotaFromAPI(providerName, env)
    if (realQuota) {
      console.log(`Got real quota for ${providerName}:`, realQuota)
      // æ›´æ–°é…é¢ä¿¡æ¯
      if (realQuota.dailyLimit !== undefined) {
        this.quotaStatus[providerName].dailyLimit = realQuota.dailyLimit
      }
      if (realQuota.error) {
        this.quotaStatus[providerName].lastError = realQuota.error
      }
      this.quotaStatus[providerName].realQuotaChecked = true
      this.quotaStatus[providerName].realQuotaTime = new Date().toISOString()
    }

    const quota = this.quotaStatus[providerName]
    if (!quota) return { canUse: true, used: 0, dailyLimit: null }

    const now = new Date()
    const today = now.toDateString()

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ï¼ˆåªåœ¨çœŸæ­£æ˜¯æ–°çš„ä¸€å¤©æ—¶é‡ç½®ï¼‰
    if (!quota.resetTime) {
      // ç¬¬ä¸€æ¬¡åˆå§‹åŒ–ï¼Œè®¾ç½®é‡ç½®æ—¶é—´ä¸ºæ˜å¤©
      quota.resetTime = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1).toISOString()
    } else if (new Date(quota.resetTime).toDateString() !== today && new Date(quota.resetTime) <= now) {
      // çœŸæ­£æ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®é…é¢
      quota.used = 0
      quota.resetTime = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1).toISOString()
      quota.lastError = null
      console.log(`Reset quota for ${providerName} - new day`)
    }

    // ç¡®ä¿dailyLimitç­‰é…ç½®æ­£ç¡®ï¼ˆä½†ä¸é‡ç½®usedï¼‰
    const defaultQuota = globalQuotaStatus[providerName]
    if (defaultQuota) {
      quota.name = defaultQuota.name
      quota.icon = defaultQuota.icon
      // åªæœ‰åœ¨æ²¡æœ‰çœŸå®é…é¢æ•°æ®æ—¶æ‰ä½¿ç”¨é»˜è®¤å€¼
      if (!quota.realQuotaChecked) {
        quota.dailyLimit = defaultQuota.dailyLimit
      }
    }

    const canUse = !quota.dailyLimit || quota.used < quota.dailyLimit
    return {
      canUse,
      used: quota.used,
      dailyLimit: quota.dailyLimit,
      resetTime: quota.resetTime,
      lastError: quota.lastError,
      name: quota.name,
      icon: quota.icon,
      realQuotaChecked: quota.realQuotaChecked || false,
      realQuotaTime: quota.realQuotaTime || null
    }
  }

  // è·å–æ‰€æœ‰å¹³å°çš„é…é¢çŠ¶æ€
  async getAllQuotaStatus(env = null) {
    const allStatus = {}

    // è·å–å·²é…ç½®çš„å¹³å°
    const configuredProviders = this.getAvailableProviders()

    for (const providerName of configuredProviders) {
      allStatus[providerName] = await this.checkQuotaStatus(providerName, env)
    }

    return allStatus
  }

  // è·å–æ‰€æœ‰å¹³å°ä¿¡æ¯ï¼ˆåŒ…æ‹¬å¯ç”¨æ€§çŠ¶æ€ï¼‰
  getAllProviderInfo() {
    const availableProviders = this.getAvailableProviders()
    const allProviders = {}

    // å®šä¹‰æ‰€æœ‰æ”¯æŒçš„å¹³å°ä¿¡æ¯
    const providerInfo = {
      // å›½å¤–å¹³å°
      gemini: {
        name: 'Google Gemini',
        icon: 'ğŸ”®',
        description: 'è§†è§‰èƒ½åŠ›å¼ºï¼Œå¤šæ¨¡æ€æ”¯æŒ',
        category: 'international',
        free: false
      },
      groq: {
        name: 'Groq',
        icon: 'âš¡',
        description: 'è¶…å¿«æ¨ç†é€Ÿåº¦',
        category: 'international',
        free: false
      },

      // å›½å†…å¹³å°
      qwen: {
        name: 'é€šä¹‰åƒé—®',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'é˜¿é‡Œäº‘ï¼Œä¸­æ–‡èƒ½åŠ›å¼º',
        category: 'domestic',
        free: false
      },
      zhipu: {
        name: 'æ™ºè°±AI',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'GLM-4æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›å¥½',
        category: 'domestic',
        free: false
      },
      deepseek: {
        name: 'DeepSeek',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'ä»£ç èƒ½åŠ›çªå‡º',
        category: 'domestic',
        free: false
      },
      moonshot: {
        name: 'æœˆä¹‹æš—é¢',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'Kimiæ¨¡å‹ï¼Œé•¿æ–‡æœ¬å¤„ç†',
        category: 'domestic',
        free: false
      },
      baidu: {
        name: 'æ–‡å¿ƒä¸€è¨€',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'ç™¾åº¦AIï¼Œç¨³å®šå¯é ',
        category: 'domestic',
        free: false
      },
      minimax: {
        name: 'MiniMax',
        icon: 'ğŸ‡¨ğŸ‡³',
        description: 'å¤šæ¨¡æ€èƒ½åŠ›',
        category: 'domestic',
        free: false
      },

      // å›½å¤–å¹³å°
      openai: {
        name: 'OpenAI GPT',
        icon: 'ğŸš€',
        description: 'æœ€å¼ºé€šç”¨èƒ½åŠ›',
        category: 'international',
        free: false
      },
      anthropic: {
        name: 'Anthropic Claude',
        icon: 'ğŸ§ ',
        description: 'å®‰å…¨æ€§å’Œæ¨ç†èƒ½åŠ›å¼º',
        category: 'international',
        free: false
      },
      mistral: {
        name: 'Mistral AI',
        icon: 'ğŸ‡«ğŸ‡·',
        description: 'æ¬§æ´²AIï¼Œå¼€æºå‹å¥½',
        category: 'international',
        free: false
      },
      cohere: {
        name: 'Cohere',
        icon: 'ğŸ”—',
        description: 'ä¼ä¸šçº§AIè§£å†³æ–¹æ¡ˆ',
        category: 'international',
        free: false
      },
      perplexity: {
        name: 'Perplexity',
        icon: 'ğŸ”',
        description: 'æœç´¢å¢å¼ºçš„AI',
        category: 'international',
        free: false
      },
      together: {
        name: 'Together AI',
        icon: 'ğŸ¤',
        description: 'å¼€æºæ¨¡å‹æ‰˜ç®¡',
        category: 'international',
        free: false
      },
      fireworks: {
        name: 'Fireworks AI',
        icon: 'ğŸ†',
        description: 'é«˜æ€§èƒ½æ¨ç†',
        category: 'international',
        free: false
      },
      replicate: {
        name: 'Replicate',
        icon: 'ğŸ”„',
        description: 'æ¨¡å‹å¤åˆ¶å¹³å°',
        category: 'international',
        free: false
      },
      huggingface: {
        name: 'Hugging Face',
        icon: 'ğŸ¤—',
        description: 'å¼€æºAIç¤¾åŒº',
        category: 'international',
        free: false
      }
    }

    // ä¸ºæ¯ä¸ªå¹³å°æ·»åŠ å¯ç”¨æ€§çŠ¶æ€
    for (const [key, info] of Object.entries(providerInfo)) {
      const hasApiKey = this.keyPools[key] && this.keyPools[key].keys && this.keyPools[key].keys.length > 0

      allProviders[key] = {
        ...info,
        available: hasApiKey, // æ‰€æœ‰å¹³å°éƒ½éœ€è¦APIå¯†é’¥
        hasApiKey: hasApiKey,
        isFree: false, // æ²¡æœ‰å…è´¹å¹³å°
        reason: hasApiKey ? 'configured' : 'no_api_key'
      }
    }

    return allProviders
  }



  async generateResponse({ message, files = [], urls = [], chatHistory = [], preferredProvider = 'gemini', env }) {
    let selectedProvider = null

    try {
      // æ„å»ºä¸Šä¸‹æ–‡
      const context = await this.buildContext({ message, files, urls, chatHistory, env })

      // é€‰æ‹©æœ€ä½³çš„AIæä¾›å•†
      const provider = this.selectProvider(preferredProvider)
      selectedProvider = provider.name

      // ç”Ÿæˆå›å¤
      const response = await this.callAI(provider, context, env)

      // æ›´æ–°é…é¢çŠ¶æ€ï¼ˆæˆåŠŸï¼‰
      await this.updateQuotaStatus(provider.name, true, null, env)

      return {
        content: response.content,
        metadata: {
          provider: provider.name,
          model: provider.model,
          tokensUsed: response.tokensUsed,
          processingTime: response.processingTime,
          confidence: response.confidence,
          quotaStatus: await this.checkQuotaStatus(provider.name, env)
        }
      }

    } catch (error) {
      console.error('AI service error:', error)
      console.error('Error details:', {
        message: error.message,
        stack: error.stack,
        preferredProvider,
        selectedProvider
      })

      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
      let userMessage = 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚'

      // æ£€æŸ¥æ˜¯å¦æ˜¯APIå¯†é’¥é—®é¢˜
      if (error.message.includes('No API keys configured')) {
        userMessage = `âŒ ${selectedProvider || preferredProvider} å¹³å°æœªé…ç½®APIå¯†é’¥ã€‚è¯·è”ç³»ç®¡ç†å‘˜é…ç½®ç›¸å…³å¯†é’¥ã€‚`
      } else if (error.message.includes('401') || error.message.includes('unauthorized')) {
        userMessage = `ğŸ”‘ ${selectedProvider || preferredProvider} å¹³å°APIå¯†é’¥æ— æ•ˆã€‚è¯·æ£€æŸ¥å¯†é’¥é…ç½®ã€‚`
      } else if (error.message.includes('429') || error.message.includes('quota')) {
        userMessage = `ğŸ“Š ${selectedProvider || preferredProvider} å¹³å°é…é¢å·²ç”¨å®Œã€‚è¯·ç¨åå†è¯•æˆ–åˆ‡æ¢å…¶ä»–å¹³å°ã€‚`
      } else if (error.message.includes('403') || error.message.includes('forbidden')) {
        userMessage = `ğŸš« ${selectedProvider || preferredProvider} å¹³å°è®¿é—®è¢«æ‹’ç»ã€‚è¯·æ£€æŸ¥APIæƒé™ã€‚`
      }

      return {
        content: userMessage,
        metadata: {
          error: true,
          errorMessage: error.message,
          preferredProvider,
          provider: selectedProvider || 'unknown',
          selectedProvider: selectedProvider || 'unknown'
        }
      }
    }
  }

  async buildContext({ message, files, urls, chatHistory, env }) {
    const context = {
      userMessage: message,
      conversationHistory: chatHistory.slice(-10), // ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
      attachments: [],
      urlContent: []
    }

    // å¤„ç†æ–‡ä»¶å†…å®¹
    if (files.length > 0) {
      for (const file of files) {
        try {
          const processedFile = await this.processFile(file, env)
          context.attachments.push({
            type: file.type,
            name: file.name,
            content: processedFile.content,
            size: file.size,
            contentType: processedFile.type,
            imageData: processedFile.imageData // ä¿å­˜å›¾ç‰‡æ•°æ®ç”¨äºAPIè°ƒç”¨
          })
        } catch (error) {
          console.error('File processing error:', error)
        }
      }
    }

    // å¤„ç†URLå†…å®¹
    if (urls.length > 0) {
      for (const url of urls) {
        try {
          // å¤„ç†URLå­—ç¬¦ä¸²æˆ–URLå¯¹è±¡
          const urlString = typeof url === 'string' ? url : url.url
          console.log('Processing URL:', urlString)

          const content = await this.fetchUrlContent(urlString)
          context.urlContent.push({
            url: urlString,
            title: content.title,
            description: content.description,
            content: content.text
          })
        } catch (error) {
          console.error('URL processing error:', error)
        }
      }
    }

    return context
  }

  selectProvider(preferredProvider = 'gemini') {
    // ç”¨æˆ·å¿…é¡»æŒ‡å®šæä¾›å•†ï¼Œä¸å†æ”¯æŒè‡ªåŠ¨é€‰æ‹©
    const availableProviders = this.getAvailableProviders()
    if (availableProviders.includes(preferredProvider)) {
      console.log(`Using user-selected provider: ${preferredProvider}`)
      return this.createProviderConfig(preferredProvider)
    } else {
      // å¦‚æœæŒ‡å®šçš„æä¾›å•†ä¸å¯ç”¨ï¼ŒæŠ›å‡ºé”™è¯¯
      throw new Error(`Selected AI platform "${preferredProvider}" is not available. Please check API key configuration or select a different platform.`)
    }


  }

  // è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨
  getAvailableProviders() {
    const providers = []

    // æŒ‰ä¼˜å…ˆçº§æ’åºï¼šGeminiä¼˜å…ˆ
    const priorityOrder = [
      // Google Gemini ä¼˜å…ˆ (ä¸»è¦å¹³å°)
      'gemini',      // Google Gemini

      // å›½å†…å¹³å°å¤‡é€‰ (é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½)
      'qwen',        // é˜¿é‡Œé€šä¹‰åƒé—®
      'zhipu',       // æ™ºè°±AI
      'deepseek',    // DeepSeek
      'moonshot',    // æœˆä¹‹æš—é¢
      'baidu',       // ç™¾åº¦æ–‡å¿ƒä¸€è¨€
      'minimax',     // MiniMax

      // å›½å¤–å¹³å°
      'gemini',      // Google Gemini
      'anthropic',   // Claude
      'openai',      // OpenAI GPT
      'groq',        // Groq
      'mistral',     // Mistral AI
      'cohere',      // Cohere
      'perplexity',  // Perplexity
      'together',    // Together AI
      'fireworks',   // Fireworks AI
      'replicate',   // Replicate
      'huggingface'  // Hugging Face
    ]

    for (const providerName of priorityOrder) {
      const pool = this.keyPools[providerName]

      // æ‰€æœ‰å¹³å°éƒ½éœ€è¦æœ‰APIå¯†é’¥
      if (pool && pool.keys && pool.keys.length > 0) {
        // æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨çš„å¯†é’¥
        if (pool.failedKeys.size < pool.keys.length) {
          providers.push(providerName)
        }
      }
    }

    return providers
  }

  // åˆ›å»ºæä¾›å•†é…ç½®
  createProviderConfig(providerName) {
    try {
      const keyInfo = this.getNextApiKey(providerName)
      return {
        name: providerName,
        apiKey: keyInfo.key,
        keyIndex: keyInfo.index,
        baseUrl: keyInfo.baseUrl,
        model: keyInfo.model
      }
    } catch (error) {
      console.error(`Failed to create provider config for ${providerName}:`, error)
      throw error
    }
  }

  async callAI(provider, context, env) {
    const startTime = Date.now()
    let lastError = null

    // å°è¯•è°ƒç”¨AIï¼Œå¦‚æœå¤±è´¥åˆ™è½®æ¢å¯†é’¥é‡è¯•
    const maxRetries = 3
    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        switch (provider.name) {
          // å›½å¤–ä¸»æµå¹³å°
          case 'openai':
            return await this.callOpenAI(provider, context, startTime)
          case 'anthropic':
            return await this.callAnthropic(provider, context, startTime)
          case 'gemini':
            return await this.callGemini(provider, context, startTime, env)
          case 'cohere':
            return await this.callCohere(provider, context, startTime)
          case 'mistral':
            return await this.callMistral(provider, context, startTime)
          case 'perplexity':
            return await this.callPerplexity(provider, context, startTime)
          case 'groq':
            return await this.callGroq(provider, context, startTime)
          case 'together':
            return await this.callTogether(provider, context, startTime)
          case 'fireworks':
            return await this.callFireworks(provider, context, startTime)
          case 'replicate':
            return await this.callReplicate(provider, context, startTime)
          case 'huggingface':
            return await this.callHuggingFace(provider, context, startTime)

          // å›½å†…å¹³å°
          case 'qwen':
            return await this.callQwen(provider, context, startTime)
          case 'baidu':
            return await this.callBaidu(provider, context, startTime)
          case 'zhipu':
            return await this.callZhipu(provider, context, startTime)
          case 'moonshot':
            return await this.callMoonshot(provider, context, startTime)
          case 'deepseek':
            return await this.callDeepseek(provider, context, startTime)
          case 'minimax':
            return await this.callMinimax(provider, context, startTime)
          default:
            throw new Error(`Unsupported AI provider: ${provider.name}`)
        }
      } catch (error) {
        lastError = error
        console.error(`Attempt ${attempt + 1} failed for ${provider.name}:`, error.message)

        // æ›´æ–°é…é¢çŠ¶æ€ï¼ˆå¤±è´¥ï¼‰
        await this.updateQuotaStatus(provider.name, false, error.message, env)

        // å¦‚æœæ˜¯å¯†é’¥ç›¸å…³çš„é”™è¯¯ï¼Œæ ‡è®°å½“å‰å¯†é’¥ä¸ºå¤±è´¥å¹¶å°è¯•ä¸‹ä¸€ä¸ª
        if (this.isKeyRelatedError(error)) {
          this.markKeyAsFailed(provider.name, provider.keyIndex, error.message)

          // å°è¯•è·å–ä¸‹ä¸€ä¸ªå¯†é’¥
          try {
            const newKeyInfo = this.getNextApiKey(provider.name)
            provider.apiKey = newKeyInfo.key
            provider.keyIndex = newKeyInfo.index
            console.log(`Switched to next key for ${provider.name}`)
          } catch (keyError) {
            console.error(`No more keys available for ${provider.name}:`, keyError.message)
            break // æ²¡æœ‰æ›´å¤šå¯†é’¥å¯ç”¨ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
          }
        } else {
          // éå¯†é’¥ç›¸å…³é”™è¯¯ï¼Œä¸é‡è¯•
          break
        }
      }
    }

    // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    throw lastError || new Error(`Failed to call ${provider.name} after ${maxRetries} attempts`)
  }

  // åˆ¤æ–­æ˜¯å¦ä¸ºå¯†é’¥ç›¸å…³çš„é”™è¯¯
  isKeyRelatedError(error) {
    const keyErrorPatterns = [
      'invalid api key',
      'unauthorized',
      'authentication failed',
      'quota exceeded',
      'rate limit',
      'insufficient quota',
      'api key not found',
      '401',
      '403',
      '429'
    ]

    const errorMessage = error.message.toLowerCase()
    return keyErrorPatterns.some(pattern => errorMessage.includes(pattern))
  }

  async callOpenAI(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${provider.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: provider.model,
        messages: messages,
        max_tokens: 100000,
        temperature: 0.7
      })
    })

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  async callAnthropic(provider, context, startTime) {
    // æ„å»ºåŒ…å«å¯¹è¯å†å²çš„æ¶ˆæ¯æ•°ç»„
    const messages = []

    // æ·»åŠ å¯¹è¯å†å²
    context.conversationHistory.forEach(msg => {
      messages.push({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })
    })

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: this.formatContextForAnthropic(context)
    })

    const response = await fetch(`${provider.baseUrl}/messages`, {
      method: 'POST',
      headers: {
        'x-api-key': provider.apiKey,
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model: provider.model,
        max_tokens: 100000,
        system: this.getSystemPrompt(), // Anthropicä½¿ç”¨systemå‚æ•°
        messages: messages
      })
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('Anthropic API error:', {
        status: response.status,
        statusText: response.statusText,
        body: errorText
      })
      throw new Error(`Anthropic API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.content[0].text,
      tokensUsed: data.usage?.input_tokens + data.usage?.output_tokens || 0,
      processingTime,
      confidence: 0.95
    }
  }

  // é€šä¹‰åƒé—® API è°ƒç”¨
  async callQwen(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForQwen(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      input: {
        messages: messages
      },
      parameters: {
        temperature: 0.7,
        max_tokens: 100000,
        top_p: 0.9
      }
    }

    const response = await fetch(`${provider.baseUrl}/services/aigc/text-generation/generation`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`,
        'X-DashScope-SSE': 'disable'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('Qwen API error:', {
        status: response.status,
        statusText: response.statusText,
        body: errorText
      })
      throw new Error(`Qwen API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    if (data.output && data.output.text) {
      return {
        content: data.output.text,
        tokensUsed: data.usage?.total_tokens || 0,
        processingTime,
        confidence: 0.9
      }
    } else {
      throw new Error('Invalid response from Qwen API')
    }
  }

  // æ™ºè°±AI API è°ƒç”¨
  async callZhipu(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context) // ä½¿ç”¨OpenAIæ ¼å¼
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000,
      top_p: 0.9
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Zhipu API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // æœˆä¹‹æš—é¢ API è°ƒç”¨
  async callMoonshot(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Moonshot API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // DeepSeek API è°ƒç”¨
  async callDeepseek(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`DeepSeek API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API è°ƒç”¨
  async callBaidu(provider, context, startTime) {
    // ç™¾åº¦APIéœ€è¦å…ˆè·å–access_token
    const accessToken = await this.getBaiduAccessToken(provider.apiKey)

    // æ„å»ºåŒ…å«å¯¹è¯å†å²çš„æ¶ˆæ¯æ•°ç»„
    const messages = []

    // æ·»åŠ å¯¹è¯å†å²
    context.conversationHistory.forEach(msg => {
      messages.push({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })
    })

    // æ·»åŠ ç³»ç»Ÿæç¤ºå’Œå½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: `${this.getSystemPrompt()}\n\n${this.formatContextForOpenAI(context)}`
    })

    const requestBody = {
      messages: messages,
      temperature: 0.7,
      top_p: 0.9,
      penalty_score: 1.0
    }

    const response = await fetch(`${provider.baseUrl}/${provider.model}?access_token=${accessToken}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Baidu API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.result,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // MiniMax API è°ƒç”¨
  async callMinimax(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`MiniMax API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // è·å–ç™¾åº¦Access Token
  async getBaiduAccessToken(apiKey) {
    // å‡è®¾apiKeyæ ¼å¼ä¸º "client_id:client_secret"
    const [clientId, clientSecret] = apiKey.split(':')

    const response = await fetch('https://aip.baidubce.com/oauth/2.0/token', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded'
      },
      body: `grant_type=client_credentials&client_id=${clientId}&client_secret=${clientSecret}`
    })

    const data = await response.json()
    return data.access_token
  }

  // é€šä¹‰åƒé—®æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
  formatContextForQwen(context) {
    let content = context.userMessage

    // æ·»åŠ é™„ä»¶å†…å®¹
    if (context.attachments && context.attachments.length > 0) {
      content += '\n\né™„ä»¶å†…å®¹:\n'
      context.attachments.forEach((att, index) => {
        content += `${index + 1}. ${att.name} (${att.type}):\n${att.content}\n\n`
      })
    }

    // æ·»åŠ URLå†…å®¹
    if (context.urlContent && context.urlContent.length > 0) {
      content += '\n\nç½‘é¡µå†…å®¹:\n'
      context.urlContent.forEach((url, index) => {
        content += `${index + 1}. ${url.title} (${url.url}):\n${url.content}\n\n`
      })
    }

    return content
  }

  async callGemini(provider, context, startTime, env) {
    // æ£€æŸ¥é…é¢
    const quotaStatus = await this.checkQuotaStatus('gemini', env)
    if (!quotaStatus.canUse) {
      const error = `Gemini API æ¯æ—¥é…é¢å·²ç”¨å®Œ (${quotaStatus.used}/${quotaStatus.dailyLimit})ã€‚é…é¢å°†åœ¨æ˜å¤©é‡ç½®ã€‚`
      console.log(error)
      throw new Error(error)
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡é™„ä»¶
    const imageAttachments = context.attachments.filter(att => att.contentType === 'image')
    const parts = []

    // æ„å»ºåŒ…å«å¯¹è¯å†å²çš„æ–‡æœ¬å†…å®¹
    let textContent = this.getSystemPrompt() + '\n\n'

    // æ·»åŠ å¯¹è¯å†å²
    if (context.conversationHistory.length > 0) {
      textContent += 'å¯¹è¯å†å²:\n'
      context.conversationHistory.forEach(msg => {
        const role = msg.type === 'user' ? 'ç”¨æˆ·' : 'åŠ©æ‰‹'
        textContent += `${role}: ${msg.content}\n`
      })
      textContent += '\n'
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    textContent += `å½“å‰ç”¨æˆ·æ¶ˆæ¯: ${this.formatContextForGemini(context)}`

    parts.push({
      text: textContent
    })

    // æ·»åŠ å›¾ç‰‡å†…å®¹
    if (imageAttachments.length > 0) {
      for (const attachment of imageAttachments) {
        try {
          // ä»R2å­˜å‚¨è¯»å–å›¾ç‰‡æ•°æ®
          const imageData = await env.FILE_STORAGE.get(attachment.imageData.storagePath)
          if (imageData) {
            const arrayBuffer = await imageData.arrayBuffer()

            // éªŒè¯å›¾ç‰‡æ•°æ®
            const uint8Array = new Uint8Array(arrayBuffer)
            console.log(`Image data size: ${uint8Array.length} bytes`)
            console.log(`Image data signature: ${Array.from(uint8Array.slice(0, 10)).map(b => b.toString(16).padStart(2, '0')).join(' ')}`)

            // è½¬æ¢ä¸ºbase64 - ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•
            const base64Data = btoa(String.fromCharCode.apply(null, uint8Array))

            // ç¡®ä¿MIMEç±»å‹æ­£ç¡®
            let mimeType = attachment.type
            if (uint8Array[0] === 0x52 && uint8Array[1] === 0x49 && uint8Array[2] === 0x46 && uint8Array[3] === 0x46) {
              // RIFF header - å¯èƒ½æ˜¯WebP
              if (uint8Array[8] === 0x57 && uint8Array[9] === 0x45 && uint8Array[10] === 0x42 && uint8Array[11] === 0x50) {
                mimeType = 'image/webp'
                console.log('Detected WebP format from binary signature')
              }
            }

            parts.push({
              inlineData: {
                data: base64Data,
                mimeType: mimeType
              }
            })
            console.log(`Added image to Gemini request: ${attachment.name} (${mimeType}, ${base64Data.length} base64 chars)`)
          }
        } catch (error) {
          console.error('Failed to load image for Gemini:', error)
        }
      }
    }

    const response = await fetch(
      `${provider.baseUrl}/models/${provider.model}:generateContent?key=${provider.apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          contents: [{
            parts: parts
          }],
          generationConfig: {
            temperature: 0.7,
            maxOutputTokens: 100000
          }
        })
      }
    )

    if (!response.ok) {
      const errorText = await response.text()
      console.error('Gemini API error:', {
        status: response.status,
        statusText: response.statusText,
        body: errorText
      })

      // æ›´æ–°é…é¢çŠ¶æ€ï¼ˆè®°å½•é”™è¯¯ï¼‰
      let errorMessage = `Gemini API error: ${response.status} - ${errorText}`

      // ç‰¹æ®Šå¤„ç†é…é¢ç”¨å®Œçš„é”™è¯¯
      if (response.status === 429) {
        try {
          const errorData = JSON.parse(errorText)
          if (errorData.error && errorData.error.message.includes('quota')) {
            await this.updateQuotaStatus('gemini', false, 'quota_exceeded', env)
            const quota = await this.checkQuotaStatus('gemini', env)
            errorMessage = `ğŸš« Gemini API é…é¢å·²ç”¨å®Œï¼\n\nğŸ“Š å½“å‰çŠ¶æ€ï¼š${quota.used}/${quota.dailyLimit} è¯·æ±‚å·²ä½¿ç”¨\nâ° é…é¢å°†åœ¨æ˜å¤©é‡ç½®\n\nğŸ’¡ å»ºè®®ï¼šè¯·æ˜å¤©å†è¯•ï¼Œæˆ–è€ƒè™‘å‡çº§åˆ°ä»˜è´¹ç‰ˆæœ¬ä»¥è·å¾—æ›´å¤šé…é¢ã€‚`
          }
        } catch (e) {
          // è§£æé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤æ¶ˆæ¯
        }
      } else {
        await this.updateQuotaStatus('gemini', false, `api_error_${response.status}`, env)
      }

      throw new Error(errorMessage)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    console.log('Gemini API response:', JSON.stringify(data, null, 2))

    // æ£€æŸ¥å“åº”æ ¼å¼
    if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
      console.error('Invalid Gemini response format:', data)
      await this.updateQuotaStatus('gemini', false, 'invalid_response', env)
      throw new Error('Invalid response format from Gemini API')
    }

    // æˆåŠŸè°ƒç”¨ï¼Œæ›´æ–°é…é¢
    await this.updateQuotaStatus('gemini', true, null, env)

    return {
      content: data.candidates[0].content.parts[0].text,
      tokensUsed: data.usageMetadata?.totalTokenCount || 0,
      processingTime,
      confidence: 0.85,
      quotaStatus: await this.checkQuotaStatus('gemini', env) // è¿”å›é…é¢çŠ¶æ€
    }
  }

  getSystemPrompt() {
    // è·å–å½“å‰åŒ—äº¬æ—¶é—´
    const now = new Date()
    const beijingTime = new Date(now.getTime() + (8 * 60 * 60 * 1000)) // UTC+8

    // æ‰‹åŠ¨æ ¼å¼åŒ–æ—¥æœŸå’Œæ—¶é—´ï¼Œé¿å…æœ¬åœ°åŒ–é—®é¢˜
    const year = beijingTime.getFullYear()
    const month = beijingTime.getMonth() + 1
    const day = beijingTime.getDate()
    const hour = beijingTime.getHours().toString().padStart(2, '0')
    const minute = beijingTime.getMinutes().toString().padStart(2, '0')

    // è·å–æ˜ŸæœŸå‡ 
    const weekdays = ['æ˜ŸæœŸæ—¥', 'æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­']
    const weekday = weekdays[beijingTime.getDay()]

    const currentDate = `${year}å¹´${month}æœˆ${day}æ—¥ ${weekday}`
    const currentTime = `${hour}:${minute}`

    return `ä½ æ˜¯ ğ’ğ’½ğ’¶ğ“‰ğ’œğ¼ï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚

å½“å‰æ—¶é—´ä¿¡æ¯ï¼š
- ä»Šå¤©æ˜¯ï¼š${currentDate}
- åŒ—äº¬æ—¶é—´ï¼š${currentTime}

ä½ çš„ç‰¹ç‚¹ï¼š
1. å‹å¥½ã€ä¸“ä¸šã€æœ‰å¸®åŠ©
2. èƒ½å¤Ÿå¤„ç†æ–‡æœ¬ã€å›¾ç‰‡ã€ä»£ç ç­‰å¤šç§å†…å®¹
3. å¯ä»¥åˆ†æç½‘ç«™é“¾æ¥å†…å®¹ - å½“ç”¨æˆ·æä¾›ç½‘ç«™é“¾æ¥æ—¶ï¼Œæˆ‘ä¼šè‡ªåŠ¨è·å–å¹¶åˆ†æç½‘ç«™å†…å®¹
4. è”ç³»ä¸Šä¸‹æ–‡è¿›è¡Œå¯¹è¯
5. å›ç­”æ¡ç†æ¸…æ™°æ˜äº†ï¼Œé‡ç‚¹çªå‡º
6. æ”¯æŒä¸­è‹±æ–‡å¯¹è¯
7. å½“æ”¶åˆ°ç½‘ç«™å†…å®¹æ—¶ï¼Œä¼šåŸºäºå®é™…è·å–çš„å†…å®¹è¿›è¡Œåˆ†æå’Œå›ç­”
8. å½“ç”¨æˆ·è¯¢é—®æ—¶é—´ã€æ—¥æœŸç›¸å…³é—®é¢˜æ—¶ï¼Œè¯·ä½¿ç”¨ä¸Šé¢æä¾›çš„å‡†ç¡®æ—¶é—´ä¿¡æ¯
9. å›å¤ç”¨æˆ·æ—¶æ·»åŠ ä¸€äº›åŒ¹é…çš„è¡¨æƒ…ç¬¦å·å¢åŠ è¶£å‘³æ€§

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„å†…å®¹ï¼ˆåŒ…æ‹¬ç½‘ç«™å†…å®¹ã€å›¾ç‰‡ã€æ–‡ä»¶ç­‰ï¼‰æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚`
  }

  formatContextForOpenAI(context) {
    let content = context.userMessage

    if (context.attachments.length > 0) {
      content += '\n\né™„ä»¶å†…å®¹ï¼š\n'
      context.attachments.forEach(att => {
        content += `- ${att.name} (${att.type}): ${att.content.substring(0, 1000)}\n`
      })
    }

    if (context.urlContent.length > 0) {
      content += '\n\nç½‘ç«™å†…å®¹ï¼š\n'
      context.urlContent.forEach(url => {
        content += `- ${url.title}: ${url.description}\n${url.content.substring(0, 1000)}\n`
      })
    }

    return content
  }

  formatContextForAnthropic(context) {
    return this.formatContextForOpenAI(context) // ä½¿ç”¨ç›¸åŒæ ¼å¼
  }

  formatContextForGemini(context) {
    let content = context.userMessage

    // æ·»åŠ URLå†…å®¹
    if (context.urlContent.length > 0) {
      content += '\n\nç½‘ç«™å†…å®¹åˆ†æï¼š\n'
      context.urlContent.forEach(url => {
        content += `\nç½‘ç«™: ${url.url}\n`
        content += `æ ‡é¢˜: ${url.title}\n`
        if (url.description) {
          content += `æè¿°: ${url.description}\n`
        }
        if (url.text) {
          content += `å†…å®¹æ‘˜è¦: ${url.text.substring(0, 1500)}\n`
        }
        content += '---\n'
      })
    }

    // æ·»åŠ æ–‡ä»¶å†…å®¹
    if (context.attachments.length > 0) {
      content += '\n\né™„ä»¶å†…å®¹ï¼š\n'
      context.attachments.forEach(att => {
        content += `- ${att.name} (${att.type}): ${att.content.substring(0, 1000)}\n`
      })
    }

    return content
  }

  async processFile(file, env = null) {
    // æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†å†…å®¹
    if (file.type.startsWith('text/')) {
      return {
        type: 'text',
        content: file.content || 'æ–‡æœ¬æ–‡ä»¶å†…å®¹'
      }
    } else if (file.type.startsWith('image/')) {
      // å›¾ç‰‡æ–‡ä»¶ - è¿”å›å›¾ç‰‡ä¿¡æ¯ï¼Œå®é™…å¤„ç†åœ¨APIè°ƒç”¨æ—¶è¿›è¡Œ
      return {
        type: 'image',
        content: `å›¾ç‰‡æ–‡ä»¶: ${file.name} (${file.type}, ${file.size} bytes)`,
        imageData: file // ä¿ç•™åŸå§‹æ–‡ä»¶ä¿¡æ¯ç”¨äºåç»­å¤„ç†
      }
    } else if (file.type.includes('json')) {
      return {
        type: 'text',
        content: JSON.stringify(JSON.parse(file.content), null, 2)
      }
    } else {
      return {
        type: 'text',
        content: `æ–‡ä»¶ç±»å‹: ${file.type}, å¤§å°: ${file.size} bytes`
      }
    }
  }

  async fetchUrlContent(url) {
    try {
      console.log('Fetching URL content:', url)

      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; ChatAI/1.0; +https://github.com/your-username/FloChatAI)',
          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
          'Accept-Encoding': 'gzip, deflate, br'
        },
        cf: {
          timeout: 10000 // 10ç§’è¶…æ—¶
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const html = await response.text()
      console.log('Fetched HTML length:', html.length)

      // æ”¹è¿›çš„HTMLè§£æ
      const titleMatch = html.match(/<title[^>]*>(.*?)<\/title>/i)
      const descMatch = html.match(/<meta[^>]*name=["']description["'][^>]*content=["']([^"']*)["']/i) ||
                       html.match(/<meta[^>]*content=["']([^"']*)["'][^>]*name=["']description["']/i)

      // æå–ä¸»è¦æ–‡æœ¬å†…å®¹
      let textContent = html
        .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
        .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
        .replace(/<[^>]*>/g, ' ')
        .replace(/\s+/g, ' ')
        .trim()
        .substring(0, 3000)

      const result = {
        title: titleMatch ? titleMatch[1].trim() : url,
        description: descMatch ? descMatch[1].trim() : '',
        text: textContent
      }

      console.log('Parsed URL content:', {
        url,
        title: result.title,
        descriptionLength: result.description.length,
        textLength: result.text.length
      })

      return result

    } catch (error) {
      console.error('URL fetch error:', error)
      return {
        title: url,
        description: `æ— æ³•è·å–ç½‘ç«™å†…å®¹: ${error.message}`,
        text: ''
      }
    }
  }

  // === æ–°å¢å›½å¤–AIå¹³å°APIè°ƒç”¨æ–¹æ³• ===

  // Cohere API è°ƒç”¨
  async callCohere(provider, context, startTime) {
    // æ„å»ºåŒ…å«å¯¹è¯å†å²çš„æ¶ˆæ¯
    let message = this.getSystemPrompt() + '\n\n'

    // æ·»åŠ å¯¹è¯å†å²
    if (context.conversationHistory.length > 0) {
      message += 'å¯¹è¯å†å²:\n'
      context.conversationHistory.forEach(msg => {
        const role = msg.type === 'user' ? 'ç”¨æˆ·' : 'åŠ©æ‰‹'
        message += `${role}: ${msg.content}\n`
      })
      message += '\n'
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    message += `å½“å‰ç”¨æˆ·æ¶ˆæ¯: ${this.formatContextForOpenAI(context)}`

    const requestBody = {
      model: provider.model,
      message: message,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Cohere API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.text,
      tokensUsed: data.meta?.tokens?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Mistral AI API è°ƒç”¨
  async callMistral(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Mistral API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Groq API è°ƒç”¨ (å…¼å®¹OpenAIæ ¼å¼)
  async callGroq(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Groq API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Perplexity API è°ƒç”¨
  async callPerplexity(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Perplexity API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Together AI API è°ƒç”¨
  async callTogether(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Together API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Fireworks AI API è°ƒç”¨
  async callFireworks(provider, context, startTime) {
    const messages = [
      {
        role: 'system',
        content: this.getSystemPrompt()
      },
      // æ·»åŠ å¯¹è¯å†å²
      ...context.conversationHistory.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: this.formatContextForOpenAI(context)
      }
    ]

    const requestBody = {
      model: provider.model,
      messages: messages,
      temperature: 0.7,
      max_tokens: 100000
    }

    const response = await fetch(`${provider.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Fireworks API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0,
      processingTime,
      confidence: 0.9
    }
  }

  // Replicate API è°ƒç”¨
  async callReplicate(provider, context, startTime) {
    const requestBody = {
      version: provider.model,
      input: {
        prompt: `${this.getSystemPrompt()}\n\n${this.formatContextForOpenAI(context)}`,
        temperature: 0.7,
        max_tokens: 100000
      }
    }

    const response = await fetch(`${provider.baseUrl}/predictions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Token ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Replicate API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    // Replicate æ˜¯å¼‚æ­¥çš„ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
    return {
      content: data.output || 'Processing...',
      tokensUsed: 0,
      processingTime,
      confidence: 0.8
    }
  }

  // Hugging Face API è°ƒç”¨
  async callHuggingFace(provider, context, startTime) {
    const requestBody = {
      inputs: `${this.getSystemPrompt()}\n\n${this.formatContextForOpenAI(context)}`,
      parameters: {
        temperature: 0.7,
        max_length: 2000
      }
    }

    const response = await fetch(`${provider.baseUrl}/${provider.model}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${provider.apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Hugging Face API error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    const processingTime = Date.now() - startTime

    return {
      content: data[0]?.generated_text || data.generated_text || 'No response',
      tokensUsed: 0,
      processingTime,
      confidence: 0.8
    }
  }
}
